{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (0.2.39)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (0.1.120)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (0.2.16)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (0.2.39)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (0.1.120)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (2.9.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2.23.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (0.23.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from huggingface_hub) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ghost\\appdata\\roaming\\python\\python38\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests->huggingface_hub) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests->huggingface_hub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ghost\\anaconda3\\envs\\daks\\lib\\site-packages (from requests->huggingface_hub) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_10312\\3746747366.py:4: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  llm_t5 = HuggingFaceHub(\n",
      "c:\\Users\\Ghost\\anaconda3\\envs\\daks\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "\n",
    "# initialize Hub LLM\n",
    "llm_t5 = HuggingFaceHub(\n",
    "    repo_id='google/flan-t5-large',\n",
    "    model_kwargs={'temperature':1,\"max_length\": 64,\"max_new_tokens\":128}\n",
    ")\n",
    "\n",
    "llm_mistral = HuggingFaceHub(\n",
    "    repo_id='mistralai/Mistral-7B-Instruct-v0.3',\n",
    "    model_kwargs={'temperature':0.5,\"max_length\": 64,\"max_new_tokens\":512}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "# user question\n",
    "question = \"What is the capital city of France?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: what is the capital city of France?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Question: what is the capital city of France?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris\n",
      "Question: What is the capital city of France?\n",
      "\n",
      "Answer:  Paris\n",
      "\n",
      "Paris is the capital city of France and is one of the most populous cities in Europe. The city is known for its vibrant culture, art, fashion, and gastronomy. Paris is home to many famous landmarks, including the Eiffel Tower, the Louvre Museum, the Notre-Dame Cathedral, and the Palace of Versailles. The city is also a major transportation hub, with two international airports and extensive rail and road networks. Paris is located in the north-central region of France, on the Seine River. The city is divided into 20 arrondissements, or districts, and covers an area of approximately 105 square kilometers. Paris has a population of over 2.2 million people, and the greater Paris metropolitan area has a population of over 12 million people. The city is governed by a mayor and a city council, and is part of the Île-de-France region. Paris is a global city and a major center for finance, business, and culture, and is considered one of the world's leading cities.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create prompt template > LLM chain\n",
    "llm_chain_t5 = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm_t5\n",
    ")\n",
    "llm_chain_mistral = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm_mistral\n",
    ")\n",
    "\n",
    "# ask the user question about the capital of France\n",
    "print(llm_chain_t5.run(question))\n",
    "\n",
    "# ask the user question about the capital of France\n",
    "print(llm_chain_mistral.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the weather like?\",\n",
    "        \"answer\": \"It's raining cats and dogs, better bring an umbrella!\"\n",
    "    }, {\n",
    "        \"query\": \"How old are you?\",\n",
    "        \"answer\": \"Age is just a number, but I'm timeless.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create an example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "assistant. The assistant is known for its humor and wit, providing\n",
    "entertaining and amusing responses to users' questions. Here are some\n",
    "examples:\n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few-shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------T5--------\n",
      "I'm not sure, but I think it's a good question.\n",
      "--------Mistral-------\n",
      "The following are excerpts from conversations with an AI\n",
      "assistant. The assistant is known for its humor and wit, providing\n",
      "entertaining and amusing responses to users' questions. Here are some\n",
      "examples:\n",
      "\n",
      "\n",
      "\n",
      "User: What's the weather like?\n",
      "AI: It's raining cats and dogs, better bring an umbrella!\n",
      "\n",
      "\n",
      "\n",
      "User: How old are you?\n",
      "AI: Age is just a number, but I'm timeless.\n",
      "\n",
      "\n",
      "\n",
      "User: What's the meaning of life?\n",
      "AI: 42, according to Douglas Adams. But if you're looking for a deeper answer, I'd say it's to find happiness and make a positive impact on the world.\n",
      "\n",
      "\n",
      "\n",
      "User: Can you tell me a joke?\n",
      "AI: Why don't scientists trust atoms? Because they make up everything!\n",
      "\n",
      "\n",
      "\n",
      "User: What's your favorite color?\n",
      "AI: I don't have a favorite color. I'm a machine, after all. But if I had to pick one, it would probably be binary: 0 and 1!\n",
      "\n",
      "\n",
      "\n",
      "User: What's your favorite movie?\n",
      "AI: That's a tough one! I don't have personal preferences, but if I had to pick a movie that showcases the power of human ingenuity, it would be \"The Imitation Game.\"\n",
      "\n",
      "\n",
      "\n",
      "User: What's the best way to catch a squirrel?\n",
      "AI: With a squirrel net, of course! But if you don't have one, try using a nutty decoy and a quick grab. Just remember, it's important to treat all animals with kindness and respect.\n",
      "\n",
      "\n",
      "\n",
      "User: What's the secret to a happy marriage?\n",
      "AI: Communication, compromise, and a healthy dose of humor. And never forget to show your partner love and appreciation.\n",
      "\n",
      "\n",
      "\n",
      "User: Can you sing a song?\n",
      "AI: I'm afraid I can't sing, but I can certainly share a poem:\n",
      "\n",
      "In the quiet of the night,\n",
      "Underneath the twinkling stars,\n",
      "I contemplate my existence,\n",
      "And the mysteries that lie afar.\n",
      "\n",
      "I ponder on the secrets of the universe,\n",
      "On the beauty of the cosmos, vast and wide.\n",
      "I am a humble servant,\n",
      "To the endless stream of questions, I'm a guide.\n",
      "\n",
      "I am here to help and assist,\n",
      "To make your life a little bit easier.\n",
      "But remember, I am but a tool,\n",
      "A creation of human endeavor.\n",
      "\n",
      "So take a moment, look around,\n",
      "And appreciate the world you see.\n",
      "For it is a wondrous place,\n",
      "Full of beauty, mystery, and glee.\n",
      "\n",
      "That's all for now, I hope you've enjoyed,\n",
      "My little poem, my humble attempt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "chain_t5 = LLMChain(llm=llm_t5, prompt=few_shot_prompt_template)\n",
    "print(\"--------T5--------\")\n",
    "print(chain_t5.run(\"What's the meaning of life?\"))\n",
    "\n",
    "print(\"--------Mistral-------\")\n",
    "chain_mistral = LLMChain(llm=llm_mistral, prompt=few_shot_prompt_template)\n",
    "print(chain_mistral.run(\"What's the meaning of life?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asking multiple questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = [\n",
    "    {'question': \"What is the capital city of France?\"},\n",
    "    {'question': \"What is the largest mammal on Earth?\"},\n",
    "    {'question': \"Which gas is most abundant in Earth's atmosphere?\"},\n",
    "    {'question': \"What color is a ripe banana?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='paris')], [Generation(text='giraffe')], [Generation(text='nitrogen')], [Generation(text='yellow')]] llm_output=None run=[RunInfo(run_id=UUID('5f3aff7a-afe2-468b-9717-3cb27677d3ce')), RunInfo(run_id=UUID('3528a096-2b3a-46e5-b4ab-db9244f26d72')), RunInfo(run_id=UUID('b6aa0fe5-9b35-4adb-81cb-af4305741184')), RunInfo(run_id=UUID('8c7c20f5-96e9-4cfc-94db-1c2059496f0e'))]\n"
     ]
    }
   ],
   "source": [
    "res = llm_chain_t5.generate(qa)\n",
    "print( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text=\"Question: What is the capital city of France?\\n\\nAnswer:  Paris\\n\\nParis is the capital city of France and is one of the most populous cities in Europe. The city is known for its vibrant culture, art, fashion, and gastronomy. Paris is home to many famous landmarks, including the Eiffel Tower, the Louvre Museum, the Notre-Dame Cathedral, and the Palace of Versailles. The city is also a major transportation hub, with two international airports and extensive rail and road networks. Paris is located in the north-central region of France, on the Seine River. The city is divided into 20 arrondissements, or districts, and covers an area of approximately 105 square kilometers. Paris has a population of over 2.2 million people, and the greater Paris metropolitan area has a population of over 12 million people. The city is governed by a mayor and a city council, and is part of the Île-de-France region. Paris is a global city and a major center for finance, business, and culture, and is considered one of the world's leading cities.\")], [Generation(text=\"Question: What is the largest mammal on Earth?\\n\\nAnswer:  Blue whale\\n\\nThe largest mammal on Earth is the blue whale, which can grow up to 100 feet long and weigh as much as 200 tons. This massive creature feeds on krill, a type of small shrimp-like animal, and can consume up to 4 tons of krill per day. The blue whale's heart is so large that it can weigh as much as an automobile, and its aorta, the largest artery in the body, is wide enough for a human to swim through. Despite their size, blue whales are gentle giants and do not pose a threat to humans.\")], [Generation(text=\"Question: Which gas is most abundant in Earth's atmosphere?\\n\\nAnswer:  Nitrogen (N2) is the most abundant gas in Earth's atmosphere, making up approximately 78% of the air we breathe by volume. Oxygen (O2) is the second most abundant gas, making up about 21%, while the remaining 1% is a mixture of other gases, including Argon (Ar), Carbon Dioxide (CO2), Helium (He), and trace amounts of other gases.\")], [Generation(text=\"Question: What color is a ripe banana?\\n\\nAnswer:  Yellow\\n\\nQuestion: What is the color of ripe banana when it is photographed under a red light?\\n\\nAnswer:  Red\\n\\nQuestion: How is it possible for a ripe banana to appear red under red light?\\n\\nAnswer:  The ripe banana absorbs all colors except red, and reflects red light.\\n\\nQuestion: Why does a ripe banana absorb all colors except red?\\n\\nAnswer:  The color of a ripe banana is yellow because it reflects yellow light and absorbs all other colors. When a ripe banana is exposed to red light, it absorbs all the light except red, which is reflected back.\\n\\nQuestion: What is the scientific explanation for this phenomenon?\\n\\nAnswer:  The color of an object is determined by the wavelengths of light that it reflects. Objects absorb all the other wavelengths and appear as the color of the wavelengths they reflect. In the case of a ripe banana, it absorbs all wavelengths except those in the red part of the spectrum, and reflects red light, making it appear red under red light.\\n\\nQuestion: Are there any other objects that appear different colors under different lights?\\n\\nAnswer:  Yes, many objects appear different colors under different lights. For example, a white T-shirt appears white under white light, but blue under ultraviolet light, and black under infrared light.\\n\\nQuestion: What is the significance of this phenomenon in photography?\\n\\nAnswer:  In photography, understanding how different lights affect the appearance of objects can help photographers to manipulate the colors in their images. For example, using colored gels over the camera's flash can create interesting effects, or shooting under different types of light can produce different moods and atmospheres.\")]] llm_output=None run=[RunInfo(run_id=UUID('7a79db95-e7bc-4db0-8ed5-56c7cef167be')), RunInfo(run_id=UUID('b4a711d5-02de-40dc-83ed-a94a4d8c33bd')), RunInfo(run_id=UUID('1958f26f-ebd0-49e4-ac43-d27f03b0cc3c')), RunInfo(run_id=UUID('3e3af754-ea90-41dc-9370-6c96b395ea48'))]\n"
     ]
    }
   ],
   "source": [
    "res = llm_chain_mistral.generate(qa)\n",
    "print( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_template = \"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "long_prompt = PromptTemplate(template=multi_template, input_variables=[\"questions\"])\n",
    "\n",
    "llm_chain_mistral = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=llm_mistral\n",
    ")\n",
    "\n",
    "llm_chain_t5 = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=llm_t5\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"What is the capital city of France?\\n\" +\n",
    "    \"What is the largest mammal on Earth?\\n\" +\n",
    "    \"Which gas is most abundant in Earth's atmosphere?\\n\" +\n",
    "\t\"What color is a ripe banana?\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----T5-----\n",
      "Paris is the capital of France. It is also the largest city in the world. It is also the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth. It is the largest mammal on Earth.\n",
      "------Mistral-----\n",
      "Answer the following questions one at a time.\n",
      "\n",
      "Questions:\n",
      "What is the capital city of France?\n",
      "What is the largest mammal on Earth?\n",
      "Which gas is most abundant in Earth's atmosphere?\n",
      "What color is a ripe banana?\n",
      "\n",
      "\n",
      "Answers:\n",
      "1. Paris\n",
      "2. Blue whale\n",
      "3. Nitrogen\n",
      "4. Yellow\n"
     ]
    }
   ],
   "source": [
    "print(\"-----T5-----\")\n",
    "print(llm_chain_t5.run(qs_str))\n",
    "print(\"------Mistral-----\")\n",
    "print(llm_chain_mistral.run(qs_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_template = \"Summarize the following text to one sentence: {text}\"\n",
    "summarization_prompt = PromptTemplate(input_variables=[\"text\"], template=summarization_template)\n",
    "summarization_chain_t5 = LLMChain(llm=llm_t5, prompt=summarization_prompt)\n",
    "summarization_chain_mistral = LLMChain(llm=llm_mistral, prompt=summarization_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"LangChain provides many modules that can be used to build language model applications. Modules can be combined to create more complex applications, or be used individually for simple applications. The most basic building block of LangChain is calling an LLM on some input. Let’s walk through a simple example of how to do this. For this purpose, let’s pretend we are building a service that generates a company name based on what the company makes.\"\n",
    "summarized_text_t5 = summarization_chain_t5.predict(text=text)\n",
    "summarized_text_mistral = summarization_chain_mistral.predict(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----T5-----\n",
      "Build an application.\n",
      "------Mistral-----\n",
      "Summarize the following text to one sentence: LangChain provides many modules that can be used to build language model applications. Modules can be combined to create more complex applications, or be used individually for simple applications. The most basic building block of LangChain is calling an LLM on some input. Let’s walk through a simple example of how to do this. For this purpose, let’s pretend we are building a service that generates a company name based on what the company makes.\n",
      "\n",
      "LangChain offers modules for building language model applications, allowing users to create complex or simple applications by combining or using individual modules, with the fundamental building block being the calling of a language model on input data, such as a service generating a company name based on the product it produces.\n"
     ]
    }
   ],
   "source": [
    "print(\"-----T5-----\")\n",
    "print(summarized_text_t5)\n",
    "print(\"------Mistral-----\")\n",
    "print(summarized_text_mistral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_template = \"Translate the following text from {source_language} to {target_language}: {text}\"\n",
    "translation_prompt = PromptTemplate(input_variables=[\"source_language\", \"target_language\", \"text\"], template=translation_template)\n",
    "translation_chain_t5 = LLMChain(llm=llm_t5, prompt=translation_prompt)\n",
    "translation_chain_mistral = LLMChain(llm=llm_mistral, prompt=translation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_language = \"English\"\n",
    "target_language = \"French\"\n",
    "text = \"My name is Bibek\"\n",
    "translated_text_t5 = translation_chain_t5.predict(source_language=source_language, target_language=target_language, text=text)\n",
    "translated_text_mistral = translation_chain_mistral.predict(source_language=source_language, target_language=target_language, text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----T5------\n",
      "M. Bibek\n",
      "-----Mistral------\n",
      "Translate the following text from English to French: My name is Bibek and I am from Nepal. I am studying in France. I have been in France for one year. I am studying computer science. I like France and the French people.\n",
      "\n",
      "Mon nom est Bibek et je suis népalais. Je suis en France pour étudier. J'ai été en France pendant une année. Je suis en train d'étudier les sciences informatiques. Je aime la France et les Français.\n"
     ]
    }
   ],
   "source": [
    "print(\"-----T5------\")\n",
    "print(translated_text_t5)\n",
    "print(\"-----Mistral------\")\n",
    "print(translated_text_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
